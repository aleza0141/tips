{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"","title":"Home"},{"location":"develop/","text":"Documentation under construction Warning This is a placeholder for future documentation.","title":"Overview"},{"location":"develop/#documentation-under-construction","text":"Warning This is a placeholder for future documentation.","title":"Documentation under construction"},{"location":"formats/","text":"Documentation under construction Warning This is a placeholder for future documentation.","title":"File formats"},{"location":"formats/#documentation-under-construction","text":"Warning This is a placeholder for future documentation.","title":"Documentation under construction"},{"location":"library/","text":"Documentation under construction Warning This is a placeholder for future documentation.","title":"Overview"},{"location":"library/#documentation-under-construction","text":"Warning This is a placeholder for future documentation.","title":"Documentation under construction"},{"location":"cli/bias/","text":"Documentation under construction Warning This is a placeholder for future documentation.","title":"tips bias"},{"location":"cli/bias/#documentation-under-construction","text":"Warning This is a placeholder for future documentation.","title":"Documentation under construction"},{"location":"cli/convert/","text":"Documentation under construction Warning This is a placeholder for future documentation.","title":"tips convert"},{"location":"cli/convert/#documentation-under-construction","text":"Warning This is a placeholder for future documentation.","title":"Documentation under construction"},{"location":"cli/subsample/","text":"Documentation under construction Warning This is a placeholder for future documentation.","title":"tips subsample"},{"location":"cli/subsample/#documentation-under-construction","text":"Warning This is a placeholder for future documentation.","title":"Documentation under construction"},{"location":"cli/wizard/","text":"Documentation under construction Warning This is a placeholder for future documentation.","title":"tips wizard"},{"location":"cli/wizard/#documentation-under-construction","text":"Warning This is a placeholder for future documentation.","title":"Documentation under construction"},{"location":"dev/dataset/","text":"Documentation under construction Warning This is a placeholder for future documentation.","title":"Dataset"},{"location":"dev/dataset/#documentation-under-construction","text":"Warning This is a placeholder for future documentation.","title":"Documentation under construction"},{"location":"dev/format/","text":"Adding a dataset format To add a file format, you need to extend the DatasetReader and DatasetWriter class in the tips.io modules. The classes define the availability of labels and how they can be read/written. The DataReader class A DataReader should at least implement a __init__ method that defines data formats given a input dataset , optionally, if the format can have variable units, a unit argument can be supplied: class MyDs ( DatasetReader ): def __init__ ( self , dataset , unit = None ): # comment attributes in `DataReader`s self . indexable = True self . size = None self . ds_spec = {} # reserved for `.iter()` or `.index()` methods self . _dsfile = dataset self . _index = None The indexable and size attribute determines how the dataset might be read, when indexable is False and size is not available, the dataset will only be read iteratively, this makes tasks like splitting the dataset more expansive, since the dataset must be enumerated once before the split can be determined. Whenever possible, it is advisable to implement the .index() function if a specific data point can be retrieved without loading the entire dataset. For plain text formats, this is possible by a fast scan through the file for certain pattern and subsequently rewind the text file with the file.seek() function, an example is the runner.RunnerLoader . The DataWriter class A DataWriter is also initialized with the dataset specifying the output location and the optional unit arugment. The .write() method should write one sample to the dataset, and the .finalize() method to finalize the writing. When implementing the write() method, it is again advisable to avoid caching the entire dataset in the memory. Reserved labels Some generally used label names are hard-coded, which have fixed dimension definitions. Name Shape Type Description coord [natoms, 3] float cartesian coordinates of atoms force [natoms, 3] float atomic forces charge [natoms, 3] float atomic chages elem [natoms] float atomic numbers cell [3, 3] float cell vectors pbc [3] bool periodic boundary condition energy [] float total energy When those data exist in the dataset, they should be named consistently. Checklist Below is a checklist for adding a new file format to the TIPS repo: Implement the format in python/io/your_format.py ; Document the file format in docs/python/io.md ; Adding a unit test case in python/test/io.py ; Submit your pull request! To make a smooth PR, also kindly check the developer setup and contributing guideline.","title":"Format"},{"location":"dev/format/#adding-a-dataset-format","text":"To add a file format, you need to extend the DatasetReader and DatasetWriter class in the tips.io modules. The classes define the availability of labels and how they can be read/written.","title":"Adding a dataset format"},{"location":"dev/format/#the-datareader-class","text":"A DataReader should at least implement a __init__ method that defines data formats given a input dataset , optionally, if the format can have variable units, a unit argument can be supplied: class MyDs ( DatasetReader ): def __init__ ( self , dataset , unit = None ): # comment attributes in `DataReader`s self . indexable = True self . size = None self . ds_spec = {} # reserved for `.iter()` or `.index()` methods self . _dsfile = dataset self . _index = None The indexable and size attribute determines how the dataset might be read, when indexable is False and size is not available, the dataset will only be read iteratively, this makes tasks like splitting the dataset more expansive, since the dataset must be enumerated once before the split can be determined. Whenever possible, it is advisable to implement the .index() function if a specific data point can be retrieved without loading the entire dataset. For plain text formats, this is possible by a fast scan through the file for certain pattern and subsequently rewind the text file with the file.seek() function, an example is the runner.RunnerLoader .","title":"The DataReader class"},{"location":"dev/format/#the-datawriter-class","text":"A DataWriter is also initialized with the dataset specifying the output location and the optional unit arugment. The .write() method should write one sample to the dataset, and the .finalize() method to finalize the writing. When implementing the write() method, it is again advisable to avoid caching the entire dataset in the memory.","title":"The DataWriter class"},{"location":"dev/format/#reserved-labels","text":"Some generally used label names are hard-coded, which have fixed dimension definitions. Name Shape Type Description coord [natoms, 3] float cartesian coordinates of atoms force [natoms, 3] float atomic forces charge [natoms, 3] float atomic chages elem [natoms] float atomic numbers cell [3, 3] float cell vectors pbc [3] bool periodic boundary condition energy [] float total energy When those data exist in the dataset, they should be named consistently.","title":"Reserved labels"},{"location":"dev/format/#checklist","text":"Below is a checklist for adding a new file format to the TIPS repo: Implement the format in python/io/your_format.py ; Document the file format in docs/python/io.md ; Adding a unit test case in python/test/io.py ; Submit your pull request! To make a smooth PR, also kindly check the developer setup and contributing guideline.","title":"Checklist"},{"location":"dev/guideline/","text":"Contributing Guidline Python coding convention The Python module of TIPS follows the black convention.","title":"Guideline"},{"location":"dev/guideline/#contributing-guidline","text":"","title":"Contributing Guidline"},{"location":"dev/guideline/#python-coding-convention","text":"The Python module of TIPS follows the black convention.","title":"Python coding convention"},{"location":"dev/guideline/#_1","text":"","title":""},{"location":"dev/module/","text":"Documentation under construction Warning This is a placeholder for future documentation.","title":"Module"},{"location":"dev/module/#documentation-under-construction","text":"Warning This is a placeholder for future documentation.","title":"Documentation under construction"},{"location":"dev/pattern/","text":"Documentation under construction Warning This is a placeholder for future documentation.","title":"Recipie"},{"location":"dev/pattern/#documentation-under-construction","text":"Warning This is a placeholder for future documentation.","title":"Documentation under construction"},{"location":"dev/setup/","text":"Developer setup The page collects information on the instructions to setup a developer's environment to work with TIPS. It is not necessary for TIPS developers to follow these setup, but following this setup helps to maintain a consistent code style and eases the process of pull request. VS Code EMACS","title":"Developer setup"},{"location":"dev/setup/#developer-setup","text":"The page collects information on the instructions to setup a developer's environment to work with TIPS. It is not necessary for TIPS developers to follow these setup, but following this setup helps to maintain a consistent code style and eases the process of pull request.","title":"Developer setup"},{"location":"dev/setup/#vs-code","text":"","title":"VS Code"},{"location":"dev/setup/#emacs","text":"","title":"EMACS"},{"location":"module/ase/","text":"ASE workflows aseMD The aseMD process takes a trained model and runs a MD trajecotry, with some limited options regarding the dynamics. For more complex processes, consider writing a customized MD process and include it in your workflow. Channels Channel Format Note (in) model file a trained ANN model (in) tag string a string specifying the MD simulation see below (in) geo file initial geometry, in any ASE recognizable format (out) traj file output trajectory Options Option Default Note -nvt/-npt nvt Ensemble -T 273 Temperature in K -P 1 Pressure in bar -dt 0.5 Time step in ps -time 100 Time in ps Source code #!/usr/bin/env Python def __main__ (): return traj __main__ ()","title":"ASE"},{"location":"module/ase/#ase-workflows","text":"","title":"ASE workflows"},{"location":"module/ase/#asemd","text":"The aseMD process takes a trained model and runs a MD trajecotry, with some limited options regarding the dynamics. For more complex processes, consider writing a customized MD process and include it in your workflow.","title":"aseMD"},{"location":"module/ase/#channels","text":"Channel Format Note (in) model file a trained ANN model (in) tag string a string specifying the MD simulation see below (in) geo file initial geometry, in any ASE recognizable format (out) traj file output trajectory","title":"Channels"},{"location":"module/ase/#options","text":"Option Default Note -nvt/-npt nvt Ensemble -T 273 Temperature in K -P 1 Pressure in bar -dt 0.5 Time step in ps -time 100 Time in ps Source code #!/usr/bin/env Python def __main__ (): return traj __main__ ()","title":"Options"},{"location":"module/cp2k/","text":"Documentation under construction Warning This is a placeholder for future documentation.","title":"CP2K"},{"location":"module/cp2k/#documentation-under-construction","text":"Warning This is a placeholder for future documentation.","title":"Documentation under construction"},{"location":"module/lammps/","text":"Documentation under construction Warning This is a placeholder for future documentation.","title":"LAMMPS"},{"location":"module/lammps/#documentation-under-construction","text":"Warning This is a placeholder for future documentation.","title":"Documentation under construction"},{"location":"module/misc/","text":"Documentation under construction Warning This is a placeholder for future documentation.","title":"Misc"},{"location":"module/misc/#documentation-under-construction","text":"Warning This is a placeholder for future documentation.","title":"Documentation under construction"},{"location":"module/pinn/","text":"Documentation under construction Warning This is a placeholder for future documentation.","title":"Documentation under construction"},{"location":"module/pinn/#documentation-under-construction","text":"Warning This is a placeholder for future documentation.","title":"Documentation under construction"},{"location":"module/tips/","text":"Documentation under construction Warning This is a placeholder for future documentation.","title":"TIPS"},{"location":"module/tips/#documentation-under-construction","text":"Warning This is a placeholder for future documentation.","title":"Documentation under construction"},{"location":"python/convert/","text":"Documentation under construction Warning This is a placeholder for future documentation.","title":"tips.bias"},{"location":"python/convert/#documentation-under-construction","text":"Warning This is a placeholder for future documentation.","title":"Documentation under construction"},{"location":"python/io/","text":"The TIPS IO module The IO module in TIPS allows for the translation between different atomistic data formats, with a special focus for AML. The core class is tips.io.Dataset , which holds the dataset and its metadata, and allows for manipulation and convertion of the data. To create datasets, the easiest way is to use the universal data loader load_ds : Usage Output from tips.io import load_ds ds = load_ds ( 'cp2k-pos-1.xyz' , frc = 'cp2k-frc-1.xyz' , cell = 'cp2k-cell.dat' , fmt = 'cp2k' ) # data can be splitted, converted ds . split ({ 'train' : 8 , 'test' : 2 }) ds . convert ( 'export.xyz' , fmt = 'ext-xyz' ) print ( ds ) # printing the dataset shows basic information about the dataset < tips . io . Dataset : size : 50 format : 'CP2K outputs' indexable : True structure : - elems : ? , int32 - coord : ? x3 , float32 - cell : 3 x3 , float32 > Detailed descriptions about the Dataset object can be found in its API documentation . Available formats Check marks are planned implementations for now Format Read Convert Note ase ASE Atoms objects cp2k CP2K data (pos, frc, and cell) deepmd DeePMD format ext-xyz Extended XYZ format lammps LAMMPS dump format runner RuNNer format Custom reader/writer It is possible to extend TIPS by registering extra reader/writers, an example for custom reader/writer can be found below: Example implementation of custom data reader and converters from tips.io.utils import tips_reader , tips_convert @tips_reader ( 'my-ase' ) def load_ase ( traj ): \"\"\" An example reader for ASE Atoms The function should return a tips Dataset, by specifying at least an generator which yields elements in the dataset one by one, and the metadata specifying the data structure. (the generator is redundent ni the below case because an ASE trajectory is indexable and has a defined size, such a generator will be defined automatically by tips) Args: traj: list of atoms Returns: tips.io.Dataset \"\"\" from tips.io import Dataset meta = { 'spec' : { 'elems' : { 'shape' : [ None ], 'dtype' : 'int32' }, 'coord' : { 'shape' : [ None , 3 ], 'dtype' : 'float32' }, 'cell' : { 'shape' : [ 3 , 3 ], 'dtype' : 'float32' } }, 'size' : len ( traj ), 'fmt' : 'Custom ASE Format' } def indexer ( i ): atoms = traj [ i ] data = { 'elems' : atoms . numbers 'coord' : atoms . positions , 'cell' : atoms . cell , } return data def generator (): for i in range ( meta [ 'size' ]): yield indexer ( i ) return Dataset ( generator = generator , meta = meta , indexer = indexer ) @tips_convert ( 'my-ase' ) def ds_to_ase ( dataset ): \"\"\" An example data converter to ASE trajectory The function must takes on dataset and optionally extra keyword arguments as inputs. There is no limitaton on the return values. Args: dataset (tips.io.Dataset): a dataset object \"\"\" from ase import Atoms traj = [ Atoms ( data [ 'elems' ], positions = data [ 'coord' ], cell = data [ 'cell' ]) for data in dataset ] return traj The additonal format will be available for data loading and conversion: ds = load_ds ([ Atoms [ 'H' ], Atoms [ 'Cu' ]], fmt = 'my-ase' ) traj = ds . convert ( fmt = 'my-ase' ) Registered datasets TIPS curates a small list of datasets that can be directly accessed via the load_ds function. For now, the list exist mainly for test and demonstrative purpose. Not Implemented yet! API documentation Not Implemented yet!","title":"tips.io"},{"location":"python/io/#the-tips-io-module","text":"The IO module in TIPS allows for the translation between different atomistic data formats, with a special focus for AML. The core class is tips.io.Dataset , which holds the dataset and its metadata, and allows for manipulation and convertion of the data. To create datasets, the easiest way is to use the universal data loader load_ds : Usage Output from tips.io import load_ds ds = load_ds ( 'cp2k-pos-1.xyz' , frc = 'cp2k-frc-1.xyz' , cell = 'cp2k-cell.dat' , fmt = 'cp2k' ) # data can be splitted, converted ds . split ({ 'train' : 8 , 'test' : 2 }) ds . convert ( 'export.xyz' , fmt = 'ext-xyz' ) print ( ds ) # printing the dataset shows basic information about the dataset < tips . io . Dataset : size : 50 format : 'CP2K outputs' indexable : True structure : - elems : ? , int32 - coord : ? x3 , float32 - cell : 3 x3 , float32 > Detailed descriptions about the Dataset object can be found in its API documentation .","title":"The TIPS IO module"},{"location":"python/io/#available-formats","text":"Check marks are planned implementations for now Format Read Convert Note ase ASE Atoms objects cp2k CP2K data (pos, frc, and cell) deepmd DeePMD format ext-xyz Extended XYZ format lammps LAMMPS dump format runner RuNNer format","title":"Available formats"},{"location":"python/io/#custom-readerwriter","text":"It is possible to extend TIPS by registering extra reader/writers, an example for custom reader/writer can be found below: Example implementation of custom data reader and converters from tips.io.utils import tips_reader , tips_convert @tips_reader ( 'my-ase' ) def load_ase ( traj ): \"\"\" An example reader for ASE Atoms The function should return a tips Dataset, by specifying at least an generator which yields elements in the dataset one by one, and the metadata specifying the data structure. (the generator is redundent ni the below case because an ASE trajectory is indexable and has a defined size, such a generator will be defined automatically by tips) Args: traj: list of atoms Returns: tips.io.Dataset \"\"\" from tips.io import Dataset meta = { 'spec' : { 'elems' : { 'shape' : [ None ], 'dtype' : 'int32' }, 'coord' : { 'shape' : [ None , 3 ], 'dtype' : 'float32' }, 'cell' : { 'shape' : [ 3 , 3 ], 'dtype' : 'float32' } }, 'size' : len ( traj ), 'fmt' : 'Custom ASE Format' } def indexer ( i ): atoms = traj [ i ] data = { 'elems' : atoms . numbers 'coord' : atoms . positions , 'cell' : atoms . cell , } return data def generator (): for i in range ( meta [ 'size' ]): yield indexer ( i ) return Dataset ( generator = generator , meta = meta , indexer = indexer ) @tips_convert ( 'my-ase' ) def ds_to_ase ( dataset ): \"\"\" An example data converter to ASE trajectory The function must takes on dataset and optionally extra keyword arguments as inputs. There is no limitaton on the return values. Args: dataset (tips.io.Dataset): a dataset object \"\"\" from ase import Atoms traj = [ Atoms ( data [ 'elems' ], positions = data [ 'coord' ], cell = data [ 'cell' ]) for data in dataset ] return traj The additonal format will be available for data loading and conversion: ds = load_ds ([ Atoms [ 'H' ], Atoms [ 'Cu' ]], fmt = 'my-ase' ) traj = ds . convert ( fmt = 'my-ase' )","title":"Custom reader/writer"},{"location":"python/io/#registered-datasets","text":"TIPS curates a small list of datasets that can be directly accessed via the load_ds function. For now, the list exist mainly for test and demonstrative purpose. Not Implemented yet!","title":"Registered datasets"},{"location":"python/io/#api-documentation","text":"Not Implemented yet!","title":"API documentation"},{"location":"python/reduction/","text":"Documentation under construction Warning This is a placeholder for future documentation.","title":"tips.reduction"},{"location":"python/reduction/#documentation-under-construction","text":"Warning This is a placeholder for future documentation.","title":"Documentation under construction"},{"location":"python/subsample/","text":"Documentation under construction Warning This is a placeholder for future documentation.","title":"tips.subsample"},{"location":"python/subsample/#documentation-under-construction","text":"Warning This is a placeholder for future documentation.","title":"Documentation under construction"},{"location":"recipe/active/","text":"Active workflows Usage The below commands generate a workflow in main.nf and then runs it via nextflow. The TIPS wizard generates a generic skeleton for designing the workflows, to futher tweak it, please refer to the annotated main.nf and nextflow.config files. commands main.nf nextflow.config tips wizard active nextflow run main.nf #!/usr/bin/env nextflow params . dataset = 'qm9' params . input = './inputs/*.yml' params . md_init = 'h2o.xyz' params . md_flag = '--nvt --T 373 --step 1000 --dt 0.5' // to be written profiles { standard { process { cpus=1 errorStrategy='ignore' withLabel: pinn {container='yqshao/pinn:master'} withLabel: tame {container='yqshao/tame:master'} } executor { name = 'local' cpus = 16 } } Strategies TIPS provides different strategies for an active leraning task, which affects the efficiency and the resulting NN. ENN : In an ENN (ensemble NN) workflow, the trajectory is propogated with an ensemble of NN models, while a subset of the trajectory is labelled according to a given uncertainty tolerance. DAS : The DAS (density-based adaptive sampling) scheme samples the configuration space by actively biasing the dynamics according to the data distribution in latent space. Other links Sample model input files Adding a custom analysis","title":"Active learning"},{"location":"recipe/active/#active-workflows","text":"","title":"Active workflows"},{"location":"recipe/active/#usage","text":"The below commands generate a workflow in main.nf and then runs it via nextflow. The TIPS wizard generates a generic skeleton for designing the workflows, to futher tweak it, please refer to the annotated main.nf and nextflow.config files. commands main.nf nextflow.config tips wizard active nextflow run main.nf #!/usr/bin/env nextflow params . dataset = 'qm9' params . input = './inputs/*.yml' params . md_init = 'h2o.xyz' params . md_flag = '--nvt --T 373 --step 1000 --dt 0.5' // to be written profiles { standard { process { cpus=1 errorStrategy='ignore' withLabel: pinn {container='yqshao/pinn:master'} withLabel: tame {container='yqshao/tame:master'} } executor { name = 'local' cpus = 16 } }","title":"Usage"},{"location":"recipe/active/#strategies","text":"TIPS provides different strategies for an active leraning task, which affects the efficiency and the resulting NN. ENN : In an ENN (ensemble NN) workflow, the trajectory is propogated with an ensemble of NN models, while a subset of the trajectory is labelled according to a given uncertainty tolerance. DAS : The DAS (density-based adaptive sampling) scheme samples the configuration space by actively biasing the dynamics according to the data distribution in latent space.","title":"Strategies"},{"location":"recipe/active/#other-links","text":"Sample model input files Adding a custom analysis","title":"Other links"},{"location":"recipe/benchmark/","text":"Benchmark workflows Usage The below commands generate a workflow in main.nf and then runs it via nextflow. The TIPS wizard generates a generic skeleton for designing the workflows, to futher tweak it, please refer to the annotated main.nf and nextflow.config files. commands main.nf nextflow.config tips wizard benchmark nextflow run main.nf #!/usr/bin/env nextflow params . dataset = 'qm9' params . input = './inputs/*.yml' params . md_init = 'h2o.xyz' params . md_flag = '--nvt --T 373 --step 1000 --dt 0.5' params . rdf_flag = '--tags OO,OH --rc 5' include { pinnTrain } from './pinn.nf' include { aseMD } from './ase.nf' include { rdf } from './analysis.nf' workflow { dataset = Channel . fromPath ( params . dataset ) input = Channel . fromPath ( params . input ) models = pinnTrain ( dataset , input ) trajs = aseMD ( models ) rdf ( trajs , rdf_tags ) } profiles { standard { process { cpus=1 errorStrategy='ignore' withLabel: pinn {container='yqshao/pinn:master'} withLabel: tame {container='yqshao/tame:master'} } executor { name = 'local' cpus = 16 } } Other links List of available datasets Sample model input files Adding a custom analysis","title":"Benchmarking"},{"location":"recipe/benchmark/#benchmark-workflows","text":"","title":"Benchmark workflows"},{"location":"recipe/benchmark/#usage","text":"The below commands generate a workflow in main.nf and then runs it via nextflow. The TIPS wizard generates a generic skeleton for designing the workflows, to futher tweak it, please refer to the annotated main.nf and nextflow.config files. commands main.nf nextflow.config tips wizard benchmark nextflow run main.nf #!/usr/bin/env nextflow params . dataset = 'qm9' params . input = './inputs/*.yml' params . md_init = 'h2o.xyz' params . md_flag = '--nvt --T 373 --step 1000 --dt 0.5' params . rdf_flag = '--tags OO,OH --rc 5' include { pinnTrain } from './pinn.nf' include { aseMD } from './ase.nf' include { rdf } from './analysis.nf' workflow { dataset = Channel . fromPath ( params . dataset ) input = Channel . fromPath ( params . input ) models = pinnTrain ( dataset , input ) trajs = aseMD ( models ) rdf ( trajs , rdf_tags ) } profiles { standard { process { cpus=1 errorStrategy='ignore' withLabel: pinn {container='yqshao/pinn:master'} withLabel: tame {container='yqshao/tame:master'} } executor { name = 'local' cpus = 16 } }","title":"Usage"},{"location":"recipe/benchmark/#other-links","text":"List of available datasets Sample model input files Adding a custom analysis","title":"Other links"},{"location":"recipe/overview/","text":"Overview","title":"Overview"},{"location":"recipe/overview/#overview","text":"","title":"Overview"},{"location":"recipe/train/","text":"Documentation under construction Warning This is a placeholder for future documentation.","title":"Documentation under construction"},{"location":"recipe/train/#documentation-under-construction","text":"Warning This is a placeholder for future documentation.","title":"Documentation under construction"},{"location":"start/alternatives/","text":"Alternatives Below lists known implementations of active atomistic machine learning codes that shares some purposes with TIPS (benchmarking MLPs or active learning with MLPs). If you are not sure about TIPS, maybe it will help you to evaluate the alternatives. OpenMM For classical force fields, OpenMM is a library https://openmm.org/ecosystem DP-GEN DP-GEN is possibly one of the earliest open-source code that automates the generation of MLPs. The code is mainly tightly integrated with the DeepPotential, and interfaces to a wide variety of QM packages ( official site , github repo ) MLAtom MLAtom is interfaced to several third-party AML libraries that allows for the benchmark of AML methods. ( official site ) Atomistic Adversal attack This is a demo project based on the Neural Force Field (NFF) code, featuring the active sampling of sampling of molecular geometries with adveral attack. ( github repo ) Related lists Composing reusable workflows is a common problem in different branches of computational sciences. Specifically for atomistic simulations, much effort was taken to bridge and interface different softwares. Those tools is better summerized in other lists provied below: Awesome workflow engines","title":"Alternatives"},{"location":"start/alternatives/#alternatives","text":"Below lists known implementations of active atomistic machine learning codes that shares some purposes with TIPS (benchmarking MLPs or active learning with MLPs). If you are not sure about TIPS, maybe it will help you to evaluate the alternatives.","title":"Alternatives"},{"location":"start/alternatives/#openmm","text":"For classical force fields, OpenMM is a library https://openmm.org/ecosystem","title":"OpenMM"},{"location":"start/alternatives/#dp-gen","text":"DP-GEN is possibly one of the earliest open-source code that automates the generation of MLPs. The code is mainly tightly integrated with the DeepPotential, and interfaces to a wide variety of QM packages ( official site , github repo )","title":"DP-GEN"},{"location":"start/alternatives/#mlatom","text":"MLAtom is interfaced to several third-party AML libraries that allows for the benchmark of AML methods. ( official site )","title":"MLAtom"},{"location":"start/alternatives/#atomistic-adversal-attack","text":"This is a demo project based on the Neural Force Field (NFF) code, featuring the active sampling of sampling of molecular geometries with adveral attack. ( github repo )","title":"Atomistic Adversal attack"},{"location":"start/alternatives/#related-lists","text":"Composing reusable workflows is a common problem in different branches of computational sciences. Specifically for atomistic simulations, much effort was taken to bridge and interface different softwares. Those tools is better summerized in other lists provied below: Awesome workflow engines","title":"Related lists"},{"location":"start/configure/","text":"Configure the workflow The nextflow config file In your workflow folder, you will find a file named nextflow.config that looks like this: Singularity Slurm profiles { standard { params { lmp_cmd = 'mpirun -np ${task.cpus} lmp_mpi' cp2k_cmd = 'mpirun -np ${task.cpus} cp2k.popt' } process { errorStrategy = 'ignore' withLabel: tips { container = 'yqshao/tips:tips-latest' } withLabel: pinn { container = 'yqshao/tips:pinn-latest' } withLabel: cp2k { container = 'yqshao/tips:cp2k-latest' } withLabel: utils { container = 'yqshao/tips:utils-latest' } withLabel: lammps { container = 'yqshao/tips:lammps-latest' }} executor { name = 'local' cpus = 4 }}} singularity { enabled = true autoMounts = true } profiles { standard { params { lmp_cmd = 'mpirun -np ${task.cpus} lmp_mpi' cp2k_cmd = 'mpirun -np ${task.cpus} cp2k.popt' } process { errorStrategy = 'ignore' withLabel: tips { container = 'yqshao/tips:tips-latest' } withLabel: pinn { container = 'yqshao/tips:pinn-latest' } withLabel: cp2k { container = 'yqshao/tips:cp2k-latest' } withLabel: utils { container = 'yqshao/tips:utils-latest' } withLabel: lammps { container = 'yqshao/tips:lammps-latest' }} executor { name = 'local' cpus = 4 }}} singularity { enabled = true autoMounts = true } The file specifies details about your computational resources that is independent of the workflow, e.g., the executable for your package, queuing system, the resource you wish to use, etc. Adding multiple profiles In the above example, the config is written to the \"standard\" profile. If you would like to share the same workflow across different computational resources, you can add additional profiles to the config, and switch them using the -profile argument when running, i.e.: Command nextflow run main.nf -profile my_profile Check the nextflow documentation for some examples. General recommandation When the project is generated with tips wizard , a minimal configuration file is automatically generated as in the above example. The default provided by TIPS might not fit your need. For instance, you might prefer the binaries compiled by your local HPC cluster than the singularity images, or you might want to allocate different resources to different types of calculations. TIPS curates a list of profiles for some of the computational resources we have access to. Those can be good starting points for you to adapt for your own need. You are also welcome to contribute your config if think it will be useful for others.","title":"Configure your run"},{"location":"start/configure/#configure-the-workflow","text":"","title":"Configure the workflow"},{"location":"start/configure/#the-nextflow-config-file","text":"In your workflow folder, you will find a file named nextflow.config that looks like this: Singularity Slurm profiles { standard { params { lmp_cmd = 'mpirun -np ${task.cpus} lmp_mpi' cp2k_cmd = 'mpirun -np ${task.cpus} cp2k.popt' } process { errorStrategy = 'ignore' withLabel: tips { container = 'yqshao/tips:tips-latest' } withLabel: pinn { container = 'yqshao/tips:pinn-latest' } withLabel: cp2k { container = 'yqshao/tips:cp2k-latest' } withLabel: utils { container = 'yqshao/tips:utils-latest' } withLabel: lammps { container = 'yqshao/tips:lammps-latest' }} executor { name = 'local' cpus = 4 }}} singularity { enabled = true autoMounts = true } profiles { standard { params { lmp_cmd = 'mpirun -np ${task.cpus} lmp_mpi' cp2k_cmd = 'mpirun -np ${task.cpus} cp2k.popt' } process { errorStrategy = 'ignore' withLabel: tips { container = 'yqshao/tips:tips-latest' } withLabel: pinn { container = 'yqshao/tips:pinn-latest' } withLabel: cp2k { container = 'yqshao/tips:cp2k-latest' } withLabel: utils { container = 'yqshao/tips:utils-latest' } withLabel: lammps { container = 'yqshao/tips:lammps-latest' }} executor { name = 'local' cpus = 4 }}} singularity { enabled = true autoMounts = true } The file specifies details about your computational resources that is independent of the workflow, e.g., the executable for your package, queuing system, the resource you wish to use, etc.","title":"The nextflow config file"},{"location":"start/configure/#adding-multiple-profiles","text":"In the above example, the config is written to the \"standard\" profile. If you would like to share the same workflow across different computational resources, you can add additional profiles to the config, and switch them using the -profile argument when running, i.e.: Command nextflow run main.nf -profile my_profile Check the nextflow documentation for some examples.","title":"Adding multiple profiles"},{"location":"start/configure/#general-recommandation","text":"When the project is generated with tips wizard , a minimal configuration file is automatically generated as in the above example. The default provided by TIPS might not fit your need. For instance, you might prefer the binaries compiled by your local HPC cluster than the singularity images, or you might want to allocate different resources to different types of calculations. TIPS curates a list of profiles for some of the computational resources we have access to. Those can be good starting points for you to adapt for your own need. You are also welcome to contribute your config if think it will be useful for others.","title":"General recommandation"},{"location":"start/first_workflow/","text":"Your first workflow In this section, you'll run the workflow you obtain from the previous step and learn some basics about Running the workflow To the workflow you get from the preview section, simply run: Command nextflow run main.nf if you have chosen the default config, nextflow will fetch the necessary singularity images and run the training on you local computer. If you are lucky, you will see the trained models as well as their training logs in you models folder. Structure of main.nf To see what is happening here, we first look at the main.nf file: main.nf #!/bin/env nextflow // Nextflow script for training and evaluation MLPs, // generated with TIPS v0.1.0 at 21:32-220503 import { trainer } from 'tips/pinn.nf' import { convert } from 'tips/tips.nf' params . ds = 'datasets/qm9' // input data params . inps = 'inputs/pinet.yml' // model inputs params . seeds = '1,2,3,4,5' // random sees to initialze params . splits = '90:10' // train,eval splits workflow { ds = Channel . fromPath ( params . ds ) input = Channel . fromPath ( params . inps ) splits = Channel . fromList ( params . split ) names = ds . combine ( inputs ). combine ( splits ). combine ( seeds ) . map { ds , inp , split , seed -> \"$ds-$inp.name-$split-$seed\" } dataset = convert ( ds , params . splits ) trainer ( dataset , input , names ) } This file defines the workflow, as well as the adjustable parameters. For instance, the \"ds\" parameter can be adjusted at runtime with nextflow run --ds datasets/water.yml . You might notice that this workflow imports some \"processes\" (such as trainer) from the other \"modules\". Looking into pinn.nf , you'll find that it defines the actual commands ran to perform the training, and the input/output thereof. In TIPS, the processes can be used interchangably so long as they share a similar input/output pattern. For example, you can easily integrate a Python-based training script into any existing workflow, so long as it consumes a dataset and output a model. Nextflow basics To list previous runs in the project folder: Command Output nextflow log TIMESTAMP DURATION RUN NAME STATUS REVISION ID SESSION ID COMMAND 2022-04-26 22:28:35 1m 13s tender_varahamihira OK e7132a82d7 4f445e64-8d54-48dd-9fea-b57d9be3e5c9 nextflow run 2022-04-26 22:52:18 1h 40m 53s tiny_brattain OK e7132a82d7 bf527311-a5d9-4f7b-b615-d50ff99e6ec5 nextflow run To restart from a past run with new parameters: Command Output nextflow run --inps 'inputs/*.yml' -resume Launching `main.nf` [disturbed_crick] - revision: 3439ecc683 executor > local (6) [85/e10f9e] process > trainner (3) [50%] 3 of 6, cached: 3 Note that nextflow automatically caches your completed tasks, with the -resume command, the tasks with the exact same input will be resued. For a more comprehensive description, check the Nextflow CLI reference . What next? You might notice that we did not touch upon any thing related to the environment, e.g., what if I need a different version of PiNN, or if I with to run the jobs in a queuing system? This is intentional since in TIPS the workflow is decoupled from the \"configuration\" of computational environment as much as possible. This design choice is to minimize the hassle when using the workflow. In the next section, you will get familiar with the nextflow.config file, where the computational resource, environment will be defined.","title":"Your first workflow"},{"location":"start/first_workflow/#your-first-workflow","text":"In this section, you'll run the workflow you obtain from the previous step and learn some basics about","title":"Your first workflow"},{"location":"start/first_workflow/#running-the-workflow","text":"To the workflow you get from the preview section, simply run: Command nextflow run main.nf if you have chosen the default config, nextflow will fetch the necessary singularity images and run the training on you local computer. If you are lucky, you will see the trained models as well as their training logs in you models folder.","title":"Running the workflow"},{"location":"start/first_workflow/#structure-of-mainnf","text":"To see what is happening here, we first look at the main.nf file: main.nf #!/bin/env nextflow // Nextflow script for training and evaluation MLPs, // generated with TIPS v0.1.0 at 21:32-220503 import { trainer } from 'tips/pinn.nf' import { convert } from 'tips/tips.nf' params . ds = 'datasets/qm9' // input data params . inps = 'inputs/pinet.yml' // model inputs params . seeds = '1,2,3,4,5' // random sees to initialze params . splits = '90:10' // train,eval splits workflow { ds = Channel . fromPath ( params . ds ) input = Channel . fromPath ( params . inps ) splits = Channel . fromList ( params . split ) names = ds . combine ( inputs ). combine ( splits ). combine ( seeds ) . map { ds , inp , split , seed -> \"$ds-$inp.name-$split-$seed\" } dataset = convert ( ds , params . splits ) trainer ( dataset , input , names ) } This file defines the workflow, as well as the adjustable parameters. For instance, the \"ds\" parameter can be adjusted at runtime with nextflow run --ds datasets/water.yml . You might notice that this workflow imports some \"processes\" (such as trainer) from the other \"modules\". Looking into pinn.nf , you'll find that it defines the actual commands ran to perform the training, and the input/output thereof. In TIPS, the processes can be used interchangably so long as they share a similar input/output pattern. For example, you can easily integrate a Python-based training script into any existing workflow, so long as it consumes a dataset and output a model.","title":"Structure of main.nf"},{"location":"start/first_workflow/#nextflow-basics","text":"To list previous runs in the project folder: Command Output nextflow log TIMESTAMP DURATION RUN NAME STATUS REVISION ID SESSION ID COMMAND 2022-04-26 22:28:35 1m 13s tender_varahamihira OK e7132a82d7 4f445e64-8d54-48dd-9fea-b57d9be3e5c9 nextflow run 2022-04-26 22:52:18 1h 40m 53s tiny_brattain OK e7132a82d7 bf527311-a5d9-4f7b-b615-d50ff99e6ec5 nextflow run To restart from a past run with new parameters: Command Output nextflow run --inps 'inputs/*.yml' -resume Launching `main.nf` [disturbed_crick] - revision: 3439ecc683 executor > local (6) [85/e10f9e] process > trainner (3) [50%] 3 of 6, cached: 3 Note that nextflow automatically caches your completed tasks, with the -resume command, the tasks with the exact same input will be resued. For a more comprehensive description, check the Nextflow CLI reference .","title":"Nextflow basics"},{"location":"start/first_workflow/#what-next","text":"You might notice that we did not touch upon any thing related to the environment, e.g., what if I need a different version of PiNN, or if I with to run the jobs in a queuing system? This is intentional since in TIPS the workflow is decoupled from the \"configuration\" of computational environment as much as possible. This design choice is to minimize the hassle when using the workflow. In the next section, you will get familiar with the nextflow.config file, where the computational resource, environment will be defined.","title":"What next?"},{"location":"start/help/","text":"Getting help If you meet any problem in using the TIPS code, you can welcome to reach us for help. Slack channel TIPS shares a discussion channel with the PiNN code: link . Issue tracker If you think there's a bug in the code, you can submit a bug report through Github. Useful links Nextflow documentation , forum and slack channel ; CP2K manual and google group ; LAMMPS documentation ; MatSci forum .","title":"Getting help"},{"location":"start/help/#getting-help","text":"If you meet any problem in using the TIPS code, you can welcome to reach us for help.","title":"Getting help"},{"location":"start/help/#slack-channel","text":"TIPS shares a discussion channel with the PiNN code: link .","title":"Slack channel"},{"location":"start/help/#issue-tracker","text":"If you think there's a bug in the code, you can submit a bug report through Github.","title":"Issue tracker"},{"location":"start/help/#useful-links","text":"Nextflow documentation , forum and slack channel ; CP2K manual and google group ; LAMMPS documentation ; MatSci forum .","title":"Useful links"},{"location":"start/install/","text":"Get started Install TIPS via pip TIPS is a chain of tools towards the construction of machine-learnt interatomic potentials. At its core, TIPS consists of a hierachy of nextflow workflows for a variety of atomistic machine learning tasks. If you are familiar with nextflow, you can run the recipes without even installing anything. For newcomers, it's recommanded to install the TIPS CLI, via the pip command: Command pip install git+https://teoroo-cmc.github.com/tips First step To get started, the easiest way is to create a new project with the interactive wizard command: Command tips wizard The wizard will walk you through the configuration of your workflow and create a folder with the necessary files. To run the worflow, you'll also need to install Nextflow (the wizard will direct you to the nextflow installation guide if it is not found). The next sections will detail the contents in the folder and the execution of the workflow.","title":"Installation"},{"location":"start/install/#get-started","text":"","title":"Get started"},{"location":"start/install/#install-tips-via-pip","text":"TIPS is a chain of tools towards the construction of machine-learnt interatomic potentials. At its core, TIPS consists of a hierachy of nextflow workflows for a variety of atomistic machine learning tasks. If you are familiar with nextflow, you can run the recipes without even installing anything. For newcomers, it's recommanded to install the TIPS CLI, via the pip command: Command pip install git+https://teoroo-cmc.github.com/tips","title":"Install TIPS via pip"},{"location":"start/install/#first-step","text":"To get started, the easiest way is to create a new project with the interactive wizard command: Command tips wizard The wizard will walk you through the configuration of your workflow and create a folder with the necessary files. To run the worflow, you'll also need to install Nextflow (the wizard will direct you to the nextflow installation guide if it is not found). The next sections will detail the contents in the folder and the execution of the workflow.","title":"First step"},{"location":"start/license/","text":"License BSD-3-Clause License Copyright \u00a9 2022, TIPS developers All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. Neither the name of Teoroo-CMC nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \u201cAS IS\u201d AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL TIPS developers BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.","title":"License"},{"location":"start/license/#license","text":"BSD-3-Clause License Copyright \u00a9 2022, TIPS developers All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. Neither the name of Teoroo-CMC nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \u201cAS IS\u201d AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL TIPS developers BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.","title":"License"},{"location":"start/references/","text":"References","title":"References"},{"location":"start/references/#references","text":"","title":"References"}]}