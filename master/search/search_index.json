{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"","title":"Home"},{"location":"develop/","text":"Documentation under construction Warning This is a placeholder for future documentation.","title":"Overview"},{"location":"develop/#documentation-under-construction","text":"Warning This is a placeholder for future documentation.","title":"Documentation under construction"},{"location":"formats/","text":"Documentation under construction Warning This is a placeholder for future documentation.","title":"File formats"},{"location":"formats/#documentation-under-construction","text":"Warning This is a placeholder for future documentation.","title":"Documentation under construction"},{"location":"library/","text":"Documentation under construction Warning This is a placeholder for future documentation.","title":"Overview"},{"location":"library/#documentation-under-construction","text":"Warning This is a placeholder for future documentation.","title":"Documentation under construction"},{"location":"cli/bias/","text":"Documentation under construction Warning This is a placeholder for future documentation.","title":"tips bias"},{"location":"cli/bias/#documentation-under-construction","text":"Warning This is a placeholder for future documentation.","title":"Documentation under construction"},{"location":"cli/convert/","text":"Documentation under construction Warning This is a placeholder for future documentation.","title":"tips convert"},{"location":"cli/convert/#documentation-under-construction","text":"Warning This is a placeholder for future documentation.","title":"Documentation under construction"},{"location":"cli/subsample/","text":"Documentation under construction Warning This is a placeholder for future documentation.","title":"tips subsample"},{"location":"cli/subsample/#documentation-under-construction","text":"Warning This is a placeholder for future documentation.","title":"Documentation under construction"},{"location":"cli/wizard/","text":"Documentation under construction Warning This is a placeholder for future documentation.","title":"tips wizard"},{"location":"cli/wizard/#documentation-under-construction","text":"Warning This is a placeholder for future documentation.","title":"Documentation under construction"},{"location":"dev/datasets/","text":"Documentation under construction Warning This is a placeholder for future documentation.","title":"Datasets"},{"location":"dev/datasets/#documentation-under-construction","text":"Warning This is a placeholder for future documentation.","title":"Documentation under construction"},{"location":"dev/guideline/","text":"Documentation under construction Warning This is a placeholder for future documentation.","title":"Guideline"},{"location":"dev/guideline/#documentation-under-construction","text":"Warning This is a placeholder for future documentation.","title":"Documentation under construction"},{"location":"dev/modules/","text":"Documentation under construction Warning This is a placeholder for future documentation.","title":"Modules"},{"location":"dev/modules/#documentation-under-construction","text":"Warning This is a placeholder for future documentation.","title":"Documentation under construction"},{"location":"dev/patterns/","text":"Documentation under construction Warning This is a placeholder for future documentation.","title":"Recipies"},{"location":"dev/patterns/#documentation-under-construction","text":"Warning This is a placeholder for future documentation.","title":"Documentation under construction"},{"location":"dev/setup/","text":"Documentation under construction Warning This is a placeholder for future documentation.","title":"Developer setup"},{"location":"dev/setup/#documentation-under-construction","text":"Warning This is a placeholder for future documentation.","title":"Documentation under construction"},{"location":"module/cp2k/","text":"Documentation under construction Warning This is a placeholder for future documentation.","title":"CP2K"},{"location":"module/cp2k/#documentation-under-construction","text":"Warning This is a placeholder for future documentation.","title":"Documentation under construction"},{"location":"module/gromacs/","text":"Documentation under construction Warning This is a placeholder for future documentation.","title":"GROMACS"},{"location":"module/gromacs/#documentation-under-construction","text":"Warning This is a placeholder for future documentation.","title":"Documentation under construction"},{"location":"module/lammps/","text":"Documentation under construction Warning This is a placeholder for future documentation.","title":"LAMMPS"},{"location":"module/lammps/#documentation-under-construction","text":"Warning This is a placeholder for future documentation.","title":"Documentation under construction"},{"location":"module/misc/","text":"Documentation under construction Warning This is a placeholder for future documentation.","title":"Misc"},{"location":"module/misc/#documentation-under-construction","text":"Warning This is a placeholder for future documentation.","title":"Documentation under construction"},{"location":"module/pinn/","text":"Documentation under construction Warning This is a placeholder for future documentation.","title":"PiNN"},{"location":"module/pinn/#documentation-under-construction","text":"Warning This is a placeholder for future documentation.","title":"Documentation under construction"},{"location":"module/tips/","text":"Documentation under construction Warning This is a placeholder for future documentation.","title":"TIPS"},{"location":"module/tips/#documentation-under-construction","text":"Warning This is a placeholder for future documentation.","title":"Documentation under construction"},{"location":"python/convert/","text":"Documentation under construction Warning This is a placeholder for future documentation.","title":"tips.bias"},{"location":"python/convert/#documentation-under-construction","text":"Warning This is a placeholder for future documentation.","title":"Documentation under construction"},{"location":"python/io/","text":"Documentation under construction Warning This is a placeholder for future documentation.","title":"tips.io"},{"location":"python/io/#documentation-under-construction","text":"Warning This is a placeholder for future documentation.","title":"Documentation under construction"},{"location":"python/reduction/","text":"Documentation under construction Warning This is a placeholder for future documentation.","title":"tips.reduction"},{"location":"python/reduction/#documentation-under-construction","text":"Warning This is a placeholder for future documentation.","title":"Documentation under construction"},{"location":"python/subsample/","text":"Documentation under construction Warning This is a placeholder for future documentation.","title":"tips.subsample"},{"location":"python/subsample/#documentation-under-construction","text":"Warning This is a placeholder for future documentation.","title":"Documentation under construction"},{"location":"recipe/active/","text":"Documentation under construction Warning This is a placeholder for future documentation.","title":"Active learning"},{"location":"recipe/active/#documentation-under-construction","text":"Warning This is a placeholder for future documentation.","title":"Documentation under construction"},{"location":"recipe/benchmark/","text":"Documentation under construction Warning This is a placeholder for future documentation.","title":"Benchmarking"},{"location":"recipe/benchmark/#documentation-under-construction","text":"Warning This is a placeholder for future documentation.","title":"Documentation under construction"},{"location":"recipe/train/","text":"Documentation under construction Warning This is a placeholder for future documentation.","title":"Training"},{"location":"recipe/train/#documentation-under-construction","text":"Warning This is a placeholder for future documentation.","title":"Documentation under construction"},{"location":"start/alternatives/","text":"Alternatives Below lists known implementations of active atomistic machine learning codes that shares some purposes with TIPS (benchmarking MLPs or active learning with MLPs). If you are not sure about TIPS, maybe it will help you to evaluate the alternatives. DP-GEN DP-GEN is possibly one of the earliest open-source code that automates the generation of MLPs. The code is mainly tightly integrated with the DeepPotential, and interfaces to a wide variety of QM packages ( official site , github repo ) MLAtom MLAtom is interfaced to several third-party AML libraries that allows for the benchmark of AML methods. ( official site ) Atomistic Adversal attack This is a demo project based on the Neural Force Field (NFF) code, featuring the active sampling of sampling of molecular geometries with adveral attack. ( github repo ) Related lists Composing reusable workflows is a common problem in different branches of computational sciences. Specifically for atomistic simulations, much effort was taken to bridge and interface different softwares. Those tools is better summerized in other lists provied below: Awesome workflow engines","title":"Alternatives"},{"location":"start/alternatives/#alternatives","text":"Below lists known implementations of active atomistic machine learning codes that shares some purposes with TIPS (benchmarking MLPs or active learning with MLPs). If you are not sure about TIPS, maybe it will help you to evaluate the alternatives.","title":"Alternatives"},{"location":"start/alternatives/#dp-gen","text":"DP-GEN is possibly one of the earliest open-source code that automates the generation of MLPs. The code is mainly tightly integrated with the DeepPotential, and interfaces to a wide variety of QM packages ( official site , github repo )","title":"DP-GEN"},{"location":"start/alternatives/#mlatom","text":"MLAtom is interfaced to several third-party AML libraries that allows for the benchmark of AML methods. ( official site )","title":"MLAtom"},{"location":"start/alternatives/#atomistic-adversal-attack","text":"This is a demo project based on the Neural Force Field (NFF) code, featuring the active sampling of sampling of molecular geometries with adveral attack. ( github repo )","title":"Atomistic Adversal attack"},{"location":"start/alternatives/#related-lists","text":"Composing reusable workflows is a common problem in different branches of computational sciences. Specifically for atomistic simulations, much effort was taken to bridge and interface different softwares. Those tools is better summerized in other lists provied below: Awesome workflow engines","title":"Related lists"},{"location":"start/configure/","text":"Configure the workflow The nextflow config file In your workflow folder, you will find a file named nextflow.config that looks like this: Singularity Slurm profiles { standard { params { lmp_cmd = 'mpirun -np ${task.cpus} lmp_mpi' cp2k_cmd = 'mpirun -np ${task.cpus} cp2k.popt' } process { errorStrategy = 'ignore' withLabel: tips { container = 'yqshao/tips:tips-latest' } withLabel: pinn { container = 'yqshao/tips:pinn-latest' } withLabel: cp2k { container = 'yqshao/tips:cp2k-latest' } withLabel: utils { container = 'yqshao/tips:utils-latest' } withLabel: lammps { container = 'yqshao/tips:lammps-latest' }} executor { name = 'local' cpus = 4 }}} singularity { enabled = true autoMounts = true } profiles { standard { params { lmp_cmd = 'mpirun -np ${task.cpus} lmp_mpi' cp2k_cmd = 'mpirun -np ${task.cpus} cp2k.popt' } process { errorStrategy = 'ignore' withLabel: tips { container = 'yqshao/tips:tips-latest' } withLabel: pinn { container = 'yqshao/tips:pinn-latest' } withLabel: cp2k { container = 'yqshao/tips:cp2k-latest' } withLabel: utils { container = 'yqshao/tips:utils-latest' } withLabel: lammps { container = 'yqshao/tips:lammps-latest' }} executor { name = 'local' cpus = 4 }}} singularity { enabled = true autoMounts = true } The file specifies details about your computational resources that is independent of the workflow, e.g., the executable for your package, queuing system, the resource you wish to use, etc. Adding multiple profiles In the above example, the config is written to the \"standard\" profile. If you would like to share the same workflow across different computational resources, you can add additional profiles to the config, and switch them using the -profile argument when running, i.e.: Command nextflow run main.nf -profile my_profile Check the nextflow documentation for some examples. General recommandation When the project is generated with tips wizard , a minimal configuration file is automatically generated as in the above example. The default provided by TIPS might not fit your need. For instance, you might prefer the binaries compiled by your local HPC cluster than the singularity images, or you might want to allocate different resources to different types of calculations. TIPS curates a list of profiles for some of the computational resources we have access to. Those can be good starting points for you to adapt for your own need. You are also welcome to contribute your config if think it will be useful for others.","title":"Configure your run"},{"location":"start/configure/#configure-the-workflow","text":"","title":"Configure the workflow"},{"location":"start/configure/#the-nextflow-config-file","text":"In your workflow folder, you will find a file named nextflow.config that looks like this: Singularity Slurm profiles { standard { params { lmp_cmd = 'mpirun -np ${task.cpus} lmp_mpi' cp2k_cmd = 'mpirun -np ${task.cpus} cp2k.popt' } process { errorStrategy = 'ignore' withLabel: tips { container = 'yqshao/tips:tips-latest' } withLabel: pinn { container = 'yqshao/tips:pinn-latest' } withLabel: cp2k { container = 'yqshao/tips:cp2k-latest' } withLabel: utils { container = 'yqshao/tips:utils-latest' } withLabel: lammps { container = 'yqshao/tips:lammps-latest' }} executor { name = 'local' cpus = 4 }}} singularity { enabled = true autoMounts = true } profiles { standard { params { lmp_cmd = 'mpirun -np ${task.cpus} lmp_mpi' cp2k_cmd = 'mpirun -np ${task.cpus} cp2k.popt' } process { errorStrategy = 'ignore' withLabel: tips { container = 'yqshao/tips:tips-latest' } withLabel: pinn { container = 'yqshao/tips:pinn-latest' } withLabel: cp2k { container = 'yqshao/tips:cp2k-latest' } withLabel: utils { container = 'yqshao/tips:utils-latest' } withLabel: lammps { container = 'yqshao/tips:lammps-latest' }} executor { name = 'local' cpus = 4 }}} singularity { enabled = true autoMounts = true } The file specifies details about your computational resources that is independent of the workflow, e.g., the executable for your package, queuing system, the resource you wish to use, etc.","title":"The nextflow config file"},{"location":"start/configure/#adding-multiple-profiles","text":"In the above example, the config is written to the \"standard\" profile. If you would like to share the same workflow across different computational resources, you can add additional profiles to the config, and switch them using the -profile argument when running, i.e.: Command nextflow run main.nf -profile my_profile Check the nextflow documentation for some examples.","title":"Adding multiple profiles"},{"location":"start/configure/#general-recommandation","text":"When the project is generated with tips wizard , a minimal configuration file is automatically generated as in the above example. The default provided by TIPS might not fit your need. For instance, you might prefer the binaries compiled by your local HPC cluster than the singularity images, or you might want to allocate different resources to different types of calculations. TIPS curates a list of profiles for some of the computational resources we have access to. Those can be good starting points for you to adapt for your own need. You are also welcome to contribute your config if think it will be useful for others.","title":"General recommandation"},{"location":"start/first_workflow/","text":"Your first workflow In this section, you'll run the workflow you obtain from the previous step and learn some basics about Running the workflow To the workflow you get from the preview section, simply run: Command nextflow run main.nf if you have chosen the default config, nextflow will fetch the necessary singularity images and run the training on you local computer. If you are lucky, you will see the trained models as well as their training logs in you models folder. Structure of main.nf To see what is happening here, we first look at the main.nf file: main.nf #!/bin/env nextflow // Nextflow script for training and evaluation MLPs, // generated with TIPS v0.1.0 at 21:32-220503 import { trainer } from 'tips/pinn.nf' import { convert } from 'tips/tips.nf' params . ds = 'datasets/qm9' // input data params . inps = 'inputs/pinet.yml' // model inputs params . seeds = '1,2,3,4,5' // random sees to initialze params . splits = '90:10' // train,eval splits workflow { ds = Channel . fromPath ( params . ds ) input = Channel . fromPath ( params . inps ) splits = Channel . fromList ( params . split ) names = ds . combine ( inputs ). combine ( splits ). combine ( seeds ) . map { ds , inp , split , seed -> \"$ds-$inp.name-$split-$seed\" } dataset = convert ( ds , params . splits ) trainer ( dataset , input , names ) } This file defines the workflow, as well as the adjustable parameters. For instance, the \"ds\" parameter can be adjusted at runtime with nextflow run --ds datasets/water.yml . You might notice that this workflow imports some \"processes\" (such as trainer) from the other \"modules\". Looking into pinn.nf , you'll find that it defines the actual commands ran to perform the training, and the input/output thereof. In TIPS, the processes can be used interchangably so long as they share a similar input/output pattern. For example, you can easily integrate a Python-based training script into any existing workflow, so long as it consumes a dataset and output a model. Nextflow basics To list previous runs in the project folder: Command Output nextflow log TIMESTAMP DURATION RUN NAME STATUS REVISION ID SESSION ID COMMAND 2022-04-26 22:28:35 1m 13s tender_varahamihira OK e7132a82d7 4f445e64-8d54-48dd-9fea-b57d9be3e5c9 nextflow run 2022-04-26 22:52:18 1h 40m 53s tiny_brattain OK e7132a82d7 bf527311-a5d9-4f7b-b615-d50ff99e6ec5 nextflow run To restart from a past run with new parameters: Command Output nextflow run --inps 'inputs/*.yml' -resume Launching `main.nf` [disturbed_crick] - revision: 3439ecc683 executor > local (6) [85/e10f9e] process > trainner (3) [50%] 3 of 6, cached: 3 Note that nextflow automatically caches your completed tasks, with the -resume command, the tasks with the exact same input will be resued. For a more comprehensive description, check the Nextflow CLI reference . What next? You might notice that we did not touch upon any thing related to the environment, e.g., what if I need a different version of PiNN, or if I with to run the jobs in a queuing system? This is intentional since in TIPS the workflow is decoupled from the \"configuration\" of computational environment as much as possible. This design choice is to minimize the hassle when using the workflow. In the next section, you will get familiar with the nextflow.config file, where the computational resource, environment will be defined.","title":"Your first workflow"},{"location":"start/first_workflow/#your-first-workflow","text":"In this section, you'll run the workflow you obtain from the previous step and learn some basics about","title":"Your first workflow"},{"location":"start/first_workflow/#running-the-workflow","text":"To the workflow you get from the preview section, simply run: Command nextflow run main.nf if you have chosen the default config, nextflow will fetch the necessary singularity images and run the training on you local computer. If you are lucky, you will see the trained models as well as their training logs in you models folder.","title":"Running the workflow"},{"location":"start/first_workflow/#structure-of-mainnf","text":"To see what is happening here, we first look at the main.nf file: main.nf #!/bin/env nextflow // Nextflow script for training and evaluation MLPs, // generated with TIPS v0.1.0 at 21:32-220503 import { trainer } from 'tips/pinn.nf' import { convert } from 'tips/tips.nf' params . ds = 'datasets/qm9' // input data params . inps = 'inputs/pinet.yml' // model inputs params . seeds = '1,2,3,4,5' // random sees to initialze params . splits = '90:10' // train,eval splits workflow { ds = Channel . fromPath ( params . ds ) input = Channel . fromPath ( params . inps ) splits = Channel . fromList ( params . split ) names = ds . combine ( inputs ). combine ( splits ). combine ( seeds ) . map { ds , inp , split , seed -> \"$ds-$inp.name-$split-$seed\" } dataset = convert ( ds , params . splits ) trainer ( dataset , input , names ) } This file defines the workflow, as well as the adjustable parameters. For instance, the \"ds\" parameter can be adjusted at runtime with nextflow run --ds datasets/water.yml . You might notice that this workflow imports some \"processes\" (such as trainer) from the other \"modules\". Looking into pinn.nf , you'll find that it defines the actual commands ran to perform the training, and the input/output thereof. In TIPS, the processes can be used interchangably so long as they share a similar input/output pattern. For example, you can easily integrate a Python-based training script into any existing workflow, so long as it consumes a dataset and output a model.","title":"Structure of main.nf"},{"location":"start/first_workflow/#nextflow-basics","text":"To list previous runs in the project folder: Command Output nextflow log TIMESTAMP DURATION RUN NAME STATUS REVISION ID SESSION ID COMMAND 2022-04-26 22:28:35 1m 13s tender_varahamihira OK e7132a82d7 4f445e64-8d54-48dd-9fea-b57d9be3e5c9 nextflow run 2022-04-26 22:52:18 1h 40m 53s tiny_brattain OK e7132a82d7 bf527311-a5d9-4f7b-b615-d50ff99e6ec5 nextflow run To restart from a past run with new parameters: Command Output nextflow run --inps 'inputs/*.yml' -resume Launching `main.nf` [disturbed_crick] - revision: 3439ecc683 executor > local (6) [85/e10f9e] process > trainner (3) [50%] 3 of 6, cached: 3 Note that nextflow automatically caches your completed tasks, with the -resume command, the tasks with the exact same input will be resued. For a more comprehensive description, check the Nextflow CLI reference .","title":"Nextflow basics"},{"location":"start/first_workflow/#what-next","text":"You might notice that we did not touch upon any thing related to the environment, e.g., what if I need a different version of PiNN, or if I with to run the jobs in a queuing system? This is intentional since in TIPS the workflow is decoupled from the \"configuration\" of computational environment as much as possible. This design choice is to minimize the hassle when using the workflow. In the next section, you will get familiar with the nextflow.config file, where the computational resource, environment will be defined.","title":"What next?"},{"location":"start/help/","text":"Getting help If you meet any problem in using the TIPS code, you can welcome to reach us for help. Slack channel TIPS shares a discussion channel with the PiNN code: link . Issue tracker If you think there's a bug in the code, you can submit a bug report through Github. Useful links Nextflow documentation , forum and slack channel ; CP2K manual and google group ; LAMMPS documentation ; MatSci forum .","title":"Getting help"},{"location":"start/help/#getting-help","text":"If you meet any problem in using the TIPS code, you can welcome to reach us for help.","title":"Getting help"},{"location":"start/help/#slack-channel","text":"TIPS shares a discussion channel with the PiNN code: link .","title":"Slack channel"},{"location":"start/help/#issue-tracker","text":"If you think there's a bug in the code, you can submit a bug report through Github.","title":"Issue tracker"},{"location":"start/help/#useful-links","text":"Nextflow documentation , forum and slack channel ; CP2K manual and google group ; LAMMPS documentation ; MatSci forum .","title":"Useful links"},{"location":"start/install/","text":"Get started Install TIPS via pip TIPS is a chain of tools towards the construction of machine-learnt interatomic potentials. At its core, TIPS consists of a hierachy of nextflow workflows for a variety of atomistic machine learning tasks. If you are familiar with nextflow, you can run the recipes without even installing anything. For newcomers, it's recommanded to install the TIPS CLI, via the pip command: Command pip install git+https://teoroo-cmc.github.com/tips First step To get started, the easiest way is to create a new project with the interactive wizard command: Command tips wizard The wizard will walk you through the configuration of your workflow and create a folder with the necessary files. To run the worflow, you'll also need to install Nextflow (the wizard will direct you to the nextflow installation guide if it is not found). The next sections will detail the contents in the folder and the execution of the workflow.","title":"Installation"},{"location":"start/install/#get-started","text":"","title":"Get started"},{"location":"start/install/#install-tips-via-pip","text":"TIPS is a chain of tools towards the construction of machine-learnt interatomic potentials. At its core, TIPS consists of a hierachy of nextflow workflows for a variety of atomistic machine learning tasks. If you are familiar with nextflow, you can run the recipes without even installing anything. For newcomers, it's recommanded to install the TIPS CLI, via the pip command: Command pip install git+https://teoroo-cmc.github.com/tips","title":"Install TIPS via pip"},{"location":"start/install/#first-step","text":"To get started, the easiest way is to create a new project with the interactive wizard command: Command tips wizard The wizard will walk you through the configuration of your workflow and create a folder with the necessary files. To run the worflow, you'll also need to install Nextflow (the wizard will direct you to the nextflow installation guide if it is not found). The next sections will detail the contents in the folder and the execution of the workflow.","title":"First step"},{"location":"start/license/","text":"License BSD-3-Clause License Copyright \u00a9 2022, TIPS developers All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. Neither the name of Teoroo-CMC nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \u201cAS IS\u201d AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL TIPS developers BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.","title":"License"},{"location":"start/license/#license","text":"BSD-3-Clause License Copyright \u00a9 2022, TIPS developers All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. Neither the name of Teoroo-CMC nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \u201cAS IS\u201d AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL TIPS developers BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.","title":"License"},{"location":"start/references/","text":"References","title":"References"},{"location":"start/references/#references","text":"","title":"References"}]}